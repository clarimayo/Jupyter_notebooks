{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1 >Week 25 Lab</h1>\n",
    "</div>\n",
    "\n",
    "### Open Ended Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What do you understand by Machine Learning? What does it mean and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is training or programming a machine to do something based on met conditions. If the model is properly trained and effective it should be able to predict of conduct the behavior we programmed it to do. In supervised learning we feed it training and test data so that next time it encounters similar data, it's able to predict the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the different Algorithms techniques in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four main algorithms techniques that we can use in machine learning are classification, regression, clustering and hybrids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification** - the process of assigning one or some among the predefined categories to each item. We use this when we want to be able to apply a category to new data.  \n",
    "**Regression**  - the process of estimating an output value based on multiple factors. We use this when we want to be able to predict the output of new data.  \n",
    "**Clustering**  - the process of segmenting a group of items in subgroups each of which contains similar ones. We do this when we want to organize new data.  \n",
    "**Hybrids** - the process of using a mixture of the tasks described above in order to make sense of data. We use this when one or more of the techniques above do not help us by itself.\n",
    "\n",
    "**Classification** seeks to label inputs into distinct classes. If there are only two classes, it's considered binary. If there are more than one it's considered multi classification.\n",
    "\n",
    "**Regression** seeks to predict a single output value given inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the difference between supervised and unsupervised machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For **Supervised Learning** we must provide proper labeling of our inputs/outputs. This is so that the algorithm can use the labels to determine if it's correct or not. We also intervene based on how the algorithm does at predicting our labels.\n",
    "\n",
    "### For **Unsupervised Learning** no labels are needed. The algorithm uses prototypes which characterizes its own cluster and the algorithm attempts to optimize for those prototypes. Whereas our supervised learning optimized by minimizing the error, unsupervised learning optimizes by maximizing the similarities between the cluster prototypes and data.\n",
    "\n",
    "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias).\n",
    "\n",
    "Essentially supervised learning involves machine learning where inputs and outputs are used in order to better train the model. We essentially prepare training data with an expected set of outcome to that data. We know if our models are correct based on how closely they predict the expected outcomes. However, we must be careful to avoid things like overfitting our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is Overfitting in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is overfitting in machine learning?\n",
    "\n",
    "So far, we've seen how with linear regressions we can calculate errors in different ways. We've also seen how in Logistic Regressions we can calculate metrics like accuracy and precision. These tools are model specific and depend on the type of algorithm we use.\n",
    "\n",
    "Overfitting is a concept that applies to all of these sorts of machine learning. If we train our model too well, it will be completely accurate for our training/test data but be brittle when dealing with new data. We'll get variance in the results to new data. If we train our model poorly, our model will be incorrect and make too many errors with new data.\n",
    "\n",
    "We've talked about this before as being the Bias vs. Variance problem.\n",
    "\n",
    "![model.png](attachment:369cea05-5f8b-4088-81ba-e6044f05f2e8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the difference between classification and regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#week 22 class 1 lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. In what situations would you use a linear regression? What do you need for a linear regression? Briefly explain the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression would be used in the instance where we want to find a correlation between an input and an output. For instance if we wanted to check if there is a correlation between growth of a plant and the amount of water it's given. We might hypothesize that the more water it gets the more it will grow, making growth the dependent variable. We tend to use scatter plots to view the relationship and if we see a \"linear relationship\" then we will go ahead and do a linear regression model on it. First, we will need to label at least one independent variable and only one dependent variable. Using Sklearn we will first split the total sample in 4 groups: 2 test (x and y) and 2 train (x and y). Second we will make a linear regression model. Third, pass the train x data in the linear model and give us a score.Fourth, we will pass our test x data to make y predictions. FInally, we will compare our y predictions to our actuals to find how accurate our model is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In what situations would you use a logistic regression? What do you need for a logistic regression? Briefly explain the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use logistic regression when we have a binary outcome meaning that there are two possibilities we want to predict. For example the possibility of someone passing or failing. The reason it has to be binary it's because the model only produce a 1 or 0 outcome. If we graph the database/csv and notice a sydmoid relationshiop, we will want to explore doing a logictic regression on it. We also have to keep in mind that sometimes the relationship might not be clear in the graph so it might not show a perfect sydmoid graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What is cross validation? Why is it useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation, sometimes called rotation estimation or out-of-sample testing, is any of various similar model validation techniques for assessing how the results of a statistical analysis will generalize to an independent data set.\n",
    "\n",
    "[Cross Validation Wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Motivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Explain the Bias vs. Variance issue and how it affects our machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bias-variance tradeoff - this tradeoff is essentially due to having to balance variability and bias. Variability is an error where our model is too sensitive to minor changes in the training set. This means for new or different training data, the results might be wildly different even if the inputs are similar. Bias is an error caused by incorrect assumptions in our learning algorithm that causes our model to not detect the relationship between features and target outputs. It's difficult to balance both and we ideally sant to choose a model that accurately captures the regularities of our training data but also generalizes well to unseen data.\n",
    "* Function complexity and amount of training data - Essentially we need the right training data for our supervised learning algorithms. If the function we're trying to predict is simple, than an \"inflexible\" learning algorithm with high bias and low variance will be able to learn it. If our functcion t is too complex, we will only be able to use a flexible learning algorithm with low bias and high variance using large amounts of data. \n",
    "* Dimensionality of the input space - If we consider too many features, we might be unable to train an effective model even if the true function only depends on a small number of those features.\n",
    "* Noise in the output values - If our output data is noisy or contains incorrect data, it will throw our model off as training a model that fits this data will be incorrect given new data without such issues. This can be an issue even if we don't have incorrect data but instead if the function we're trying to model is too complex for our learning algorithm\n",
    "\n",
    "\n",
    "# Important Concepts in machine learning\n",
    "\n",
    "### Underfitting vs. Overfitting.\n",
    "\n",
    "![image.png](attachment:63dc84f4-be93-4110-8dea-ca11332462d0.png)\n",
    "\n",
    "This is an important concept to consider when doing any sort of machine learning. \n",
    "\n",
    "When a model is overfitted, it performs very accurately with the training data.\n",
    "\n",
    "When a model is underfitted, it performs poorly with the training data.\n",
    "\n",
    "It seems like overfitting is better than underfitting based on this. However if our model is overfitted, it is very accurate for our training data because, essentially, we trained it to predict/classify our training data. It knows exactly how to perform with the data it was trained with but that **DOES NOT** mean it will perform well with new data. In fact, often times it will perform poorly with new data. As it knows how to deal with the training data and not unseen data. \n",
    "\n",
    "This problem is very common in financial math when creating trading algorithms. We can use past data to create models that perform very well with the back-data (such as historical stock data) but that doesn't mean it will even be profitable if it's allowed to make trades. \n",
    "\n",
    "### Bias/Variance Tradeoff\n",
    "\n",
    "Bias - is the machine learning algorithm's ability to learn the same wrong thing. \n",
    "\n",
    "Variance - is the machine learning algorithm's ability to learn random things unrelated to the real signals.\n",
    "\n",
    "![image.png](attachment:d521f4b8-7a15-48e7-a442-44a07a8745fd.png)\n",
    "\n",
    "The more complex our model, the lower the bias. If we add more features and/or complexity to our model, there's a lower chance that it continues to learn incorrectly.\n",
    "\n",
    "The less complex our model, the lower the variance. If we add more features/complexity to our model, our machine learning algorithm can pick up on things we don't want it to and even if data is similar, the small discrepencies can cause a high variance in the outputs.\n",
    "\n",
    "So we need to balance the model complexity in order to have both low bias and low variance.\n",
    "\n",
    "![image.png](attachment:a0db3461-0024-45f8-a3fa-4692063011bb.png)\n",
    "\n",
    "Important note: Bias and variance can be affected by things like our data, chosen features and parameters of our machine learning algorithm. However there are some situations where a specific machine learning algorithm isn't productive for the type of problem it's hoping to be able to handle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Explain the sklearn method `test_train_split`. Why do we use it?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "100% data:    test_size: 25%. (12.5% x_test, 12.5% y_test).       75% (37.5% y_train, 37.5% x_train)\n",
    "this will determine the performance of your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Why do we calculate errors for supervised learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#week 25 class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What is $R^{2}$ and why do we use it to analyze the fitness of our linear regressions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is the $R^{2}$ or the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
    "It's essentially the proportion of the variance in the dependent variable that is predictable from the independent variables. Meaning it's giving us information about the \"goodness of fit\". A $R^{2}$ ranges between 0 and 1. 1 implies the dependent variable is perfectly predictable from the independent variable. 0 implies that the dependent variables are not predictable from the independent variables. We ideally want a model with an $R^{2}$ to be closer to 1. However, there are instances of trading firms making millions off of a $R^{2}$ of 0.07. Ultimately it isn't a definitive \"grade\"/\"score\" for our line of best fit and we can still gain insights from a linear regression with a low $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Explain what the metrics we use to evaluate the performance of our logistic regressions mean (accuracy, precision, recall). What is a confusion matrix and what does it help us understand?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Also known as log odds and logit, logistic regression is very similar to the linear regressions we've done. However the goal of logistic regression is to model the probability that data is part of a default class. In this sense it's able to perform binary classification.\n",
    "\n",
    "**Wait, regression for classification???**\n",
    "\n",
    "Is it possible to use regression to get a value between 0 and 1 and simply round to get a binary value?\n",
    "\n",
    "**NO.** The reason for this is, that the values we get do not necessarily lie between 0 and 1, so how should we deal with a -42 as our response value?\n",
    "\n",
    "![image.png](attachment:2cef1262-3e70-45d7-a0c1-e13881367554.png)\n",
    "\n",
    "As you can see in the above illustration, an arbitrary selected value x={-1, 2} will be placed on the line somewhere in the red zone and therefore, not allow us to derive a response value that is either (at least) between or at best exactly 0 or 1. We need a function that looks like the following:\n",
    "\n",
    "![image.png](attachment:96abe41b-5a2a-484e-8d2b-7b69f40e567c.png)\n",
    "\n",
    "The huge advantage is that even an infinitely small number is mapped to “close to” zero and will not be somewhere beyond our boundary.\n",
    "\n",
    "Logistic regression is a linear method, but the predictions are transformed (or map) using the logistic function. The impact of this is that we can no longer understand the predictions as a linear combination of the inputs as we can with linear regression, for example, continuing on from above, the model can be stated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices\n",
    "\n",
    "A confusion matrix is a table that is used to evaluate the performance of a classification model. You can also visualize the performance of an algorithm. The fundamental of a confusion matrix is the number of correct and incorrect predictions are summed up class-wise.\n",
    "\n",
    "Accuracy - What fraction of predictions did our model get right?   \n",
    "Precision - What proportion of positive identifications were actually correct?  \n",
    "Recall - What proportion of actual positives were identified correctly?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
